{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a90c4ce9",
   "metadata": {},
   "source": [
    "## <span style=\"color:orange; font-weight:bold\">GeoPOINT – Synthetic Point Generator for Geospatial Applications</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450a6b4c-799f-421c-b95d-ef4810148c68",
   "metadata": {},
   "source": [
    "### <span style=\"color:red; font-weight:bold\">Structure of the GeoPOINT Script</span>\n",
    "\n",
    "This notebook consists of the following key components:\n",
    "\n",
    "- **Importing required libraries** for numerical processing, visualization, symbolic computation, and file handling.\n",
    "&nbsp;\n",
    "- **User configuration parameters.**  \n",
    "  These parameters define the number of points, transformation settings, and the characteristics of synthetic noise and geodetic distortion.\n",
    "&nbsp;\n",
    "- **Generation of synthetic points** on a spherical surface in the fixed (global) frame.  \n",
    "  Three variants are supported:\n",
    "  1. Ideal points (noise-free);  \n",
    "  2. Points with added random Gaussian noise;  \n",
    "  3. Points with combined random noise and geodetic distortion model (simulating real-world measurement errors).  \n",
    "&nbsp;\n",
    "- **Transformation of point coordinates** into a local (body) frame using parameters defined in the configuration.\n",
    "\n",
    "- **Export of both coordinate sets** (fixed and local) to Excel (`.xlsx`) files for further analysis or benchmarking.\n",
    "\n",
    "- **Visualization and statistics** summarizing the generated and transformed data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8716dc-b712-4cf2-9fc0-1cf30d433e31",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkgreen; font-weight:bold\">Importing Required Libraries</span>\n",
    "\n",
    "This section imports the Python libraries used throughout the notebook.\n",
    "\n",
    "- **NumPy** and **pandas** are used for numerical computation and tabular data handling.\n",
    "- **Matplotlib** (with `mpl_toolkits.mplot3d`) is used for 3D visualization.\n",
    "- **SymPy** is used for symbolic representation of rotation matrices.\n",
    "- **JSON** and **os** provide configuration file support and system integration.\n",
    "- **openpyxl** is used internally by `pandas` for exporting Excel spreadsheets.\n",
    "\n",
    "All libraries used are open-source and compatible with standard scientific Python environments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3953bb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, site\n",
    "print(sys.executable)\n",
    "print(site.getsitepackages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33674cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, numpy as np, pandas as pd, matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import sympy as sp\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    import open3d as o3d\n",
    "    _HAS_O3D = True\n",
    "except Exception:\n",
    "    _HAS_O3D = False\n",
    "\n",
    "try:\n",
    "    import scipy, scipy.stats as st\n",
    "    _HAS_SCIPY = True\n",
    "except Exception:\n",
    "    _HAS_SCIPY = False\n",
    "\n",
    "print(\"Versions → numpy:\", np.__version__, \"| pandas:\", pd.__version__,\n",
    "      \"| matplotlib:\", matplotlib.__version__, \"| sympy:\", sp.__version__,\n",
    "      \"| open3d:\", getattr(o3d, \"__version__\", \"n/a\"),\n",
    "      \"| scipy:\", getattr(scipy, \"__version__\", \"n/a\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa27185b-fcd1-41dd-850e-991fef0f26d6",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkgreen; font-weight:bold\">User Configuration Parameters</span>\n",
    "\n",
    "This dictionary contains all key parameters governing synthetic point generation,  \n",
    "geodetic error simulation, spatial transformation, and the addition of measurement noise.  \n",
    "All values can be freely edited in this notebook and reflect typical properties of total stations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaac8431-4feb-436a-a59a-d0a7b4ebaf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Configuration Parameters (editable by the user) ===\n",
    "\n",
    "config = {\n",
    "    # --- Point generation (fixed frame) ---\n",
    "    \"npoints\": 50,  # Number of synthetic points to generate\n",
    "    \"radius\": 50.0,  # Nominal radius of the generated spherical surface [m]\n",
    "\n",
    "    # Geodetic error model (used for distortion)\n",
    "    \"A\": 0.005,      # Distance meter constant error (instrument offset) [m]\n",
    "    \"B\": 7.0,        # Distance-dependent error (proportional term) [ppm]\n",
    "    \"angle_noise_arcsec\": 1.0,  # Simulated instrument angular precision (standard deviation) [arcseconds]\n",
    "\n",
    "    # --- Rotation parameters (in grads) ---\n",
    "    \"roll\": 5,       # Rotation about X axis (clockwise)\n",
    "    \"pitch\": 5,      # Rotation about Y axis (anticlockwise)\n",
    "    \"yaw\": 40,       # Rotation about Z axis (clockwise)\n",
    "\n",
    "    # --- Translation parameters (in meters) ---\n",
    "    \"dx\": 10.0,      # Translation along X axis\n",
    "    \"dy\": 10.0,      # Translation along Y axis\n",
    "    \"dz\": 2.0,       # Translation along Z axis\n",
    "\n",
    "    # --- Noise added to transformed points (body frame) ---\n",
    "    \"gaussian_std\": 0.01,   # Standard deviation of Gaussian noise [m]\n",
    "    \"bias\": 0.002          # Constant bias added to all coordinates [m]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382d48d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Input Source Configuration ===\n",
    "# This section controls the source of input points for GeoPOINT.\n",
    "#\n",
    "# Available modes:\n",
    "#   1. \"synthetic\"\n",
    "#      - Uses internally generated synthetic points (default).\n",
    "#      - Generation parameters are defined in the main `config` dictionary\n",
    "#        (npoints, radius, Gaussian noise, EDM distortion, etc.).\n",
    "#\n",
    "#   2. \"pcd\"\n",
    "#      - Loads a point cloud file in .pcd format via Open3D.\n",
    "#      - If path=\"auto\": automatically fetches a small demo dataset\n",
    "#        (DemoICPPointClouds from open3d.data).\n",
    "#      - If path=\"<your_file>.pcd\": loads the given local PCD file.\n",
    "#      - Options:\n",
    "#          * downsample_n: randomly downsample to this many points.\n",
    "#          * center_on_mean: if True, subtract centroid before processing.\n",
    "#\n",
    "#   3. \"csv\"\n",
    "#      - Loads points from a CSV or TXT file with XYZ columns.\n",
    "#      - path=\"<your_file>.csv\" must be provided.\n",
    "#      - `csv` dictionary allows customization:\n",
    "#          * delimiter: field separator (default \",\")\n",
    "#          * usecols: which columns correspond to X,Y,Z (0-based indices)\n",
    "#          * skiprows: how many header lines to skip\n",
    "#\n",
    "# Other options:\n",
    "#   - random_seed: controls reproducibility of random downsampling.\n",
    "#\n",
    "# Example usage:\n",
    "#   INPUT_CFG = {\"source\":\"synthetic\"}                # synthetic test points\n",
    "#   INPUT_CFG = {\"source\":\"pcd\", \"path\":\"auto\"}       # Open3D demo cloud\n",
    "#   INPUT_CFG = {\"source\":\"pcd\", \"path\":\"scan.pcd\"}   # load your own PCD\n",
    "#   INPUT_CFG = {\"source\":\"csv\", \"path\":\"points.csv\",\n",
    "#                \"csv\":{\"delimiter\":\",\",\"usecols\":[0,1,2]}}\n",
    "#\n",
    "# Note: Only one source is active at a time.\n",
    "\n",
    "INPUT_CFG = {\n",
    "    \"source\": \"pcd\",                  # \"synthetic\" | \"pcd\" | \"csv\"\n",
    "    \"path\": \"auto\",                   # \"auto\" uses Open3D sample; or provide a real file path\n",
    "    \"csv\": {\"delimiter\": \",\", \"usecols\": [0,1,2], \"skiprows\": 0},\n",
    "    \"downsample_n\": None,             # e.g. 200_000 for random downsampling\n",
    "    \"center_on_mean\": False,          # subtract centroid if True\n",
    "    \"random_seed\": 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acea506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Real-data auto sample + loaders ===\n",
    "# This block implements input loaders for different sources:\n",
    "#\n",
    "# - \"synthetic\":\n",
    "#     Uses synthetic points generated in the notebook and passed as `synthetic_xyz`.\n",
    "#\n",
    "# - \"pcd\":\n",
    "#     Loads a point cloud in .pcd format using Open3D.\n",
    "#     * If path=\"auto\": download a small sample (DemoICPPointClouds) via open3d.data.\n",
    "#     * If path=\"<your_file>.pcd\": load the given local file.\n",
    "#\n",
    "# - \"csv\":\n",
    "#     Loads XYZ points from a CSV/TXT file.\n",
    "#     The `cfg[\"csv\"]` dictionary controls delimiter, which columns are used as X,Y,Z,\n",
    "#     and how many header rows to skip.\n",
    "#\n",
    "# Extra options (applied regardless of source):\n",
    "#   * downsample_n: random subsampling to reduce very dense clouds.\n",
    "#   * center_on_mean: if True, subtracts centroid to center the point cloud.\n",
    "#\n",
    "# Tip for real-data experiments:\n",
    "#   After loading a real dataset (pcd/csv), you can create a \"clean\" and \"noisy\"\n",
    "#   pair for error/uncertainty validation using `add_real_noise_pair(...)`.\n",
    "#   This allows the same plotting/validation workflow as for synthetic data.\n",
    "\n",
    "\n",
    "def _ensure_open3d():\n",
    "    if not _HAS_O3D:\n",
    "        raise ImportError(\"Open3D is required for PCD I/O and auto samples. \"\n",
    "                          \"Install with: conda install -c conda-forge open3d\")\n",
    "\n",
    "def _auto_sample_pcd_path() -> Path:\n",
    "    \"\"\"Download a tiny real-data sample and return a PCD path.\"\"\"\n",
    "    _ensure_open3d()\n",
    "    # Option 1: classic ICP demo point clouds (couple of .pcd files)\n",
    "    sample = o3d.data.DemoICPPointClouds()\n",
    "    return Path(sample.paths[0])  # e.g., cloud_bin_0.pcd\n",
    "\n",
    "def _load_pcd(path_str: str) -> np.ndarray:\n",
    "    _ensure_open3d()\n",
    "    p = Path(path_str)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"PCD not found: {p}\")\n",
    "    pcd = o3d.io.read_point_cloud(str(p))\n",
    "    pts = np.asarray(pcd.points, dtype=float)\n",
    "    if pts.ndim != 2 or pts.shape[1] < 3:\n",
    "        raise ValueError(f\"PCD must contain XYZ; got shape {pts.shape}\")\n",
    "    return pts[:, :3]\n",
    "\n",
    "def _load_csv_xyz(path_str: str, cfg_csv: dict) -> np.ndarray:\n",
    "    p = Path(path_str)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"CSV not found: {p}\")\n",
    "    arr = np.loadtxt(\n",
    "        p,\n",
    "        delimiter=cfg_csv.get(\"delimiter\", \",\"),\n",
    "        usecols=cfg_csv.get(\"usecols\", [0,1,2]),\n",
    "        skiprows=cfg_csv.get(\"skiprows\", 0),\n",
    "    )\n",
    "    arr = np.atleast_2d(arr).astype(float)\n",
    "    if arr.shape[1] != 3:\n",
    "        raise ValueError(f\"CSV must have exactly 3 columns (XYZ); got shape {arr.shape}\")\n",
    "    return arr\n",
    "\n",
    "def load_points_from_source(cfg: dict, synthetic_xyz: np.ndarray | None = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Return XYZ (N,3). If source='synthetic', use provided synthetic_xyz.\n",
    "    If source='pcd' and path='auto', download a tiny Open3D sample (DemoICPPointClouds).\n",
    "    If source='csv', read XYZ from CSV according to cfg['csv'].\n",
    "    Optional random downsampling and centering are applied.\n",
    "    \"\"\"\n",
    "    src = cfg.get(\"source\", \"synthetic\").lower()\n",
    "    rng = np.random.default_rng(cfg.get(\"random_seed\", 42))\n",
    "\n",
    "    if src == \"synthetic\":\n",
    "        if synthetic_xyz is None:\n",
    "            raise ValueError(\"Pass synthetic_xyz from your generation step.\")\n",
    "        X = synthetic_xyz\n",
    "\n",
    "    elif src == \"pcd\":\n",
    "        path = cfg.get(\"path\", \"auto\")\n",
    "        if isinstance(path, str) and path.lower() == \"auto\":\n",
    "            p = _auto_sample_pcd_path()\n",
    "        else:\n",
    "            p = Path(path)\n",
    "        X = _load_pcd(str(p))\n",
    "\n",
    "    elif src == \"csv\":\n",
    "        X = _load_csv_xyz(cfg[\"path\"], cfg.get(\"csv\", {}))\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown source: {src}\")\n",
    "\n",
    "    # Optional random downsampling (useful if the cloud is very dense)\n",
    "    ds = cfg.get(\"downsample_n\", None)\n",
    "    if ds is not None and X.shape[0] > ds:\n",
    "        idx = rng.choice(X.shape[0], size=ds, replace=False)\n",
    "        X = X[idx]\n",
    "\n",
    "    # Optional centering\n",
    "    if cfg.get(\"center_on_mean\", False):\n",
    "        X = X - X.mean(axis=0, keepdims=True)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a88cd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Publication-ready plotting (vector export, larger fonts)\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update({\n",
    "    \"font.size\": 14, \"axes.titlesize\": 16, \"axes.labelsize\": 14,\n",
    "    \"legend.fontsize\": 12, \"xtick.labelsize\": 12, \"ytick.labelsize\": 12,\n",
    "    \"figure.dpi\": 300\n",
    "})\n",
    "\n",
    "def savefig_vec(path: str):\n",
    "    \"\"\"Save current Matplotlib figure as vector (SVG/PDF) with tight bbox.\"\"\"\n",
    "    Path(path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(path, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833f1702-eee2-4727-84e3-0ad3497d850a",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkgreen; font-weight:bold\">Generation of Synthetic Points – Fixed Frame</span>\n",
    "\n",
    "In this step, synthetic 3D points are generated over a spherical surface to simulate geodetic observations \n",
    "in an ideal global coordinate system (fixed frame).\n",
    "\n",
    "The point generation can apply three different modes of increasing realism:\n",
    "\n",
    "- **Ideal (noise-free):** applies no disturbance; purely mathematical coordinates, uniformly distributed on the sphere.\n",
    "- **With random Gaussian noise:** applies stochastic errors by perturbing angles or Cartesian coordinates.\n",
    "- **With geodetic distortion model:** applies both random noise and systematic errors based on typical properties of a Total Station, \n",
    "  including EDM (Electronic Distance Meter) range error parameters (`A`, `B`) and angular precision (in arcseconds) as defined in the `config` dictionary.\n",
    "\n",
    "The selected variant can be easily changed by switching the called function below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52c1f30-d31d-44d2-b60f-e324465b823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_angles(config):\n",
    "    \"\"\"\n",
    "    Generate base spherical angles (theta, phi) for reproducible point sets.\n",
    "    \"\"\"\n",
    "    npoints = config[\"npoints\"]\n",
    "    theta = np.random.uniform(0, 2 * np.pi, npoints)\n",
    "    phi = np.arccos(1 - 2 * np.random.uniform(0, 1, npoints))\n",
    "    return theta, phi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f5b54b-1376-4905-aa36-fbdf2eebb8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_spherical(config, theta=None, phi=None):\n",
    "    \"\"\"\n",
    "    Generate ideal 3D points uniformly distributed on the surface of a sphere,\n",
    "    representing noise-free geodetic observations from a fixed global reference frame.\n",
    "\n",
    "    Parameters:\n",
    "        config (dict): Dictionary containing generation parameters:\n",
    "            - 'npoints': Number of points to generate.\n",
    "            - 'radius': Nominal distance from origin [m].\n",
    "        theta (np.ndarray, optional): Predefined azimuthal angles [rad].\n",
    "        phi (np.ndarray, optional): Predefined zenith angles [rad].\n",
    "\n",
    "    Returns:\n",
    "        points (np.ndarray): 3×N array of Cartesian coordinates [m].\n",
    "        theta (np.ndarray): Azimuthal angles [rad].\n",
    "        phi (np.ndarray): Zenith angles [rad].\n",
    "    \"\"\"\n",
    "    npoints = config[\"npoints\"]\n",
    "    radius = config[\"radius\"]\n",
    "\n",
    "    # --- Generate or use predefined angles ---\n",
    "    if theta is None or phi is None:\n",
    "        theta = np.random.uniform(0, 2 * np.pi, npoints)\n",
    "        phi = np.arccos(1 - 2 * np.random.uniform(0, 1, npoints))\n",
    "\n",
    "    # --- Convert spherical to Cartesian coordinates ---\n",
    "    x = radius * np.sin(phi) * np.cos(theta)\n",
    "    y = radius * np.sin(phi) * np.sin(theta)\n",
    "    z = radius * np.cos(phi)\n",
    "\n",
    "    return np.vstack((x, y, z)), theta, phi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52efce49-0d19-46da-8e80-4773bb99acfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_spherical_with_noise(config, theta=None, phi=None):\n",
    "    \"\"\"\n",
    "    Generate 3D points on a spherical surface with added Gaussian noise to angles,\n",
    "    then convert to Cartesian coordinates and scale by user-defined radius.\n",
    "\n",
    "    Parameters:\n",
    "        config (dict): Includes 'npoints', 'radius', and 'angle_noise_arcsec'.\n",
    "        theta (np.ndarray, optional): Base azimuthal angles [rad] to perturb.\n",
    "        phi (np.ndarray, optional): Base zenith angles [rad] to perturb.\n",
    "\n",
    "    Returns:\n",
    "        points (np.ndarray): 3×N array of noisy 3D coordinates [m]\n",
    "        theta (np.ndarray): perturbed azimuthal angles [rad]\n",
    "        phi (np.ndarray): perturbed zenith angles [rad]\n",
    "    \"\"\"\n",
    "    npoints = config[\"npoints\"]\n",
    "    radius = config[\"radius\"]\n",
    "\n",
    "    # Arcseconds to radians conversion\n",
    "    rho = 180 * 3600 / np.pi  # arcseconds per radian\n",
    "    angle_noise = config[\"angle_noise_arcsec\"] / rho\n",
    "\n",
    "    # Generate or copy angles\n",
    "    if theta is None or phi is None:\n",
    "        theta = np.random.uniform(0, 2 * np.pi, npoints)\n",
    "        phi = np.arccos(1 - 2 * np.random.uniform(0, 1, npoints))\n",
    "    else:\n",
    "        # Ensure correct size\n",
    "        assert len(theta) == npoints and len(phi) == npoints, \"Angle arrays must match npoints\"\n",
    "        theta = theta.copy()\n",
    "        phi = phi.copy()\n",
    "\n",
    "    # Add Gaussian angular noise\n",
    "    theta += angle_noise * np.random.randn(npoints)\n",
    "    phi += angle_noise * np.random.randn(npoints)\n",
    "\n",
    "    # Spherical to Cartesian conversion\n",
    "    x = radius * np.sin(phi) * np.cos(theta)\n",
    "    y = radius * np.sin(phi) * np.sin(theta)\n",
    "    z = radius * np.cos(phi)\n",
    "\n",
    "    return np.vstack((x, y, z)), theta, phi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b022bf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Build global points (synthetic by default, optionally replaced by real XYZ) ===\n",
    "\n",
    "# 1) Choose synthetic variant (keep your current choice)\n",
    "#    - ideal, noise-free:\n",
    "Xg_3xN, theta, phi = uniform_spherical(config)\n",
    "#    - or Gaussian angular-noise version:\n",
    "# Xg_3xN, theta, phi = uniform_spherical_with_noise(config)\n",
    "\n",
    "# Ensure shape is (N, 3) for downstream steps\n",
    "Xg_synth = Xg_3xN.T  # from (3, N) -> (N, 3)\n",
    "\n",
    "# 2) Optional override with real data (PCD/CSV) based on INPUT_CFG\n",
    "#    If INPUT_CFG[\"source\"] == \"synthetic\" -> X_global stays synthetic.\n",
    "#    If \"pcd\"/\"csv\" -> loader will read real XYZ and return (N,3).\n",
    "X_global = load_points_from_source(INPUT_CFG, synthetic_xyz=Xg_synth)\n",
    "\n",
    "print(\"X_global shape:\", X_global.shape, \"| source:\", INPUT_CFG[\"source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c8c2fb-2f8c-4654-8d99-de72351f8edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_spherical_with_geodetic_distortion(config, theta=None, phi=None):\n",
    "    \"\"\"\n",
    "    Generate synthetic 3D points using a geodetic error model that includes both angular noise \n",
    "    and EDM-based range errors representative of typical total station measurements.\n",
    "\n",
    "    Parameters:\n",
    "        config (dict): Configuration dictionary with the following keys:\n",
    "            - npoints: Number of points to generate\n",
    "            - radius: Nominal distance from origin [m]\n",
    "            - A: Constant EDM error [m]\n",
    "            - B: Proportional EDM error [ppm]\n",
    "            - angle_noise_arcsec: Angular noise (standard deviation) [arcseconds]\n",
    "        theta (np.ndarray, optional): Base azimuth angles [rad]\n",
    "        phi (np.ndarray, optional): Base zenith angles [rad]\n",
    "\n",
    "    Returns:\n",
    "        points (np.ndarray): 3×N array of perturbed 3D coordinates [m]\n",
    "        theta (np.ndarray): Azimuth angles with angular noise [rad]\n",
    "        phi (np.ndarray): Zenith angles with angular noise [rad]\n",
    "        R (np.ndarray): Simulated range from origin for each point [m], including EDM errors\n",
    "    \"\"\"\n",
    "    npoints = config[\"npoints\"]\n",
    "    radius = config[\"radius\"]\n",
    "    A = config[\"A\"]\n",
    "    B = config[\"B\"]\n",
    "\n",
    "    # Arcseconds to radians conversion\n",
    "    rho = 180 * 3600 / np.pi\n",
    "    angle_noise = config[\"angle_noise_arcsec\"] / rho\n",
    "\n",
    "    # Generate or copy base angles\n",
    "    if theta is None or phi is None:\n",
    "        theta = np.random.uniform(0, 2 * np.pi, npoints)\n",
    "        phi = np.arccos(1 - 2 * np.random.uniform(0, 1, npoints))\n",
    "    else:\n",
    "        assert len(theta) == npoints and len(phi) == npoints, \"Angle arrays must match npoints\"\n",
    "        theta = theta.copy()\n",
    "        phi = phi.copy()\n",
    "\n",
    "    # Add angular noise\n",
    "    theta += angle_noise * np.random.randn(npoints)\n",
    "    phi += angle_noise * np.random.randn(npoints)\n",
    "\n",
    "    # Convert to unit direction vectors\n",
    "    x_unit = np.sin(phi) * np.cos(theta)\n",
    "    y_unit = np.sin(phi) * np.sin(theta)\n",
    "    z_unit = np.cos(phi)\n",
    "\n",
    "    # Ideal range\n",
    "    S = radius * np.ones_like(x_unit)\n",
    "\n",
    "    # Add EDM noise\n",
    "    m_S = A + B * 1e-6 * S  # B in ppm\n",
    "    R = S + m_S * np.random.randn(npoints)\n",
    "\n",
    "    # Scale vectors by range\n",
    "    x = R * x_unit\n",
    "    y = R * y_unit\n",
    "    z = R * z_unit\n",
    "\n",
    "    return np.vstack((x, y, z)), theta, phi, R\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972b7c5f-e77a-4810-9ede-65a2769f1507",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkgreen; font-weight:bold\">Coordinates Transformation – Body Frame</span>\n",
    "\n",
    "In this step, the synthetic 3D points generated in the fixed (global) frame are transformed  \n",
    "into a local coordinate system (body frame) defined by user-specified parameters.\n",
    "\n",
    "The transformation consists of:\n",
    "\n",
    "- **Translation** along the X, Y, and Z axes;  \n",
    "- **Rotation** (roll, pitch, yaw), applied in a defined order using standard rotation matrices;  \n",
    "- Optional **scaling**, if needed, to simulate dimensional adjustments.\n",
    "\n",
    "Rotation angles are specified in **gradians**, following geodetic conventions,  \n",
    "and are internally converted to **radians** prior to matrix computation.\n",
    "\n",
    "This step emulates typical geodetic operations such as aligning local measurements  \n",
    "(e.g., from a vessel or offshore platform) with a known reference coordinate system.\n",
    "\n",
    "The transformed coordinates are subsequently made available for export, benchmarking, or further analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c657e4e4-eeec-46b2-8164-297c5fa6506f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Rotation and Translation to Local Frame (Body Frame) ===\n",
    "\n",
    "# --- Load rotation and translation parameters from config ---\n",
    "roll = config[\"roll\"]\n",
    "pitch = config[\"pitch\"]\n",
    "yaw = config[\"yaw\"]\n",
    "dx = config[\"dx\"]\n",
    "dy = config[\"dy\"]\n",
    "dz = config[\"dz\"]\n",
    "\n",
    "# --- Convert rotation angles from grads to radians ---\n",
    "to_rad = np.pi / 200\n",
    "rx = roll * to_rad\n",
    "ry = pitch * to_rad\n",
    "rz = yaw * to_rad\n",
    "\n",
    "# --- Define symbolic variables for rotation angles ---\n",
    "rx_sym, ry_sym, rz_sym = sp.symbols('rx ry rz')\n",
    "\n",
    "# --- Symbolic rotation matrices ---\n",
    "Rx_sym = sp.Matrix([\n",
    "    [1, 0, 0],\n",
    "    [0, sp.cos(rx_sym), sp.sin(rx_sym)],\n",
    "    [0, -sp.sin(rx_sym), sp.cos(rx_sym)]\n",
    "])\n",
    "\n",
    "Ry_sym = sp.Matrix([\n",
    "    [sp.cos(ry_sym), 0, -sp.sin(ry_sym)],\n",
    "    [0, 1, 0],\n",
    "    [sp.sin(ry_sym), 0, sp.cos(ry_sym)]\n",
    "])\n",
    "\n",
    "Rz_sym = sp.Matrix([\n",
    "    [sp.cos(rz_sym), sp.sin(rz_sym), 0],\n",
    "    [-sp.sin(rz_sym), sp.cos(rz_sym), 0],\n",
    "    [0, 0, 1]\n",
    "])\n",
    "\n",
    "# --- Combined symbolic rotation matrix ---\n",
    "R_sym = Rz_sym * Ry_sym * Rx_sym\n",
    "R_numerical = R_sym.subs({rx_sym: rx, ry_sym: ry, rz_sym: rz})\n",
    "R = np.array(R_numerical.evalf()).astype(np.float64)\n",
    "\n",
    "# --- Define symbolic variables for parametric rotation matrix ---\n",
    "a1, a2, a3 = sp.symbols('a1 a2 a3')\n",
    "b1, b2, b3 = sp.symbols('b1 b2 b3')\n",
    "c1, c2, c3 = sp.symbols('c1 c2 c3')\n",
    "\n",
    "R_sym_symbols = R_sym.subs({\n",
    "    R_sym[0, 0]: a1, R_sym[0, 1]: b1, R_sym[0, 2]: c1,\n",
    "    R_sym[1, 0]: a2, R_sym[1, 1]: b2, R_sym[1, 2]: c2,\n",
    "    R_sym[2, 0]: a3, R_sym[2, 1]: b3, R_sym[2, 2]: c3\n",
    "})\n",
    "\n",
    "# --- Define translation vector ---\n",
    "T = np.array([[dx], [dy], [dz]])\n",
    "\n",
    "# --- Generate base spherical coordinates (shared for all variants) ---\n",
    "P_base, theta_base, phi_base = uniform_spherical(config)\n",
    "\n",
    "# --- Define generator functions with shared angular base ---\n",
    "generators = [\n",
    "    (\"ideal\", lambda cfg: (P_base, theta_base, phi_base)),\n",
    "    (\"with_noise\", lambda cfg: uniform_spherical_with_noise(cfg, theta=theta_base, phi=phi_base)),\n",
    "    (\"with_geodetic_distortion\", lambda cfg: uniform_spherical_with_geodetic_distortion(cfg, theta=theta_base, phi=phi_base))\n",
    "]\n",
    "\n",
    "# --- (Optional) prepend real-data generator if INPUT_CFG requests it ---\n",
    "if INPUT_CFG.get(\"source\", \"synthetic\").lower() != \"synthetic\":\n",
    "    # X_global pochodzi z wcześniejszej komórki: load_points_from_source(...)\n",
    "    # Zwracamy (3, N) żeby interfejs był taki sam jak w wariantach syntetycznych\n",
    "    generators = [(\"real_input\", lambda cfg: (X_global.T, None, None))] + generators\n",
    "\n",
    "# --- Prepare dictionary to store transformed point sets ---\n",
    "transformed_sets = {}\n",
    "\n",
    "# --- Iterate through each generator and apply transformation ---\n",
    "for label, generator in generators:\n",
    "    print(f\"\\n\\033[1m=== Transforming points: {label} ===\\033[0m\")\n",
    "\n",
    "    result = generator(config)\n",
    "\n",
    "    if len(result) == 3:\n",
    "        points, theta, phi = result\n",
    "    else:\n",
    "        points, theta, phi, _ = result\n",
    "\n",
    "    # Ensure shape (3, N)\n",
    "    P = points if points.shape[0] == 3 else points.T\n",
    "\n",
    "    # Apply transformation\n",
    "    PP = R @ P + T\n",
    "\n",
    "    # Optional post-transform noise in the body frame ---\n",
    "    sigma = float(config.get(\"gaussian_std\", 0.0))  # [m]\n",
    "    bias  = float(config.get(\"bias\", 0.0))          # [m]\n",
    "\n",
    "    if (sigma != 0.0 or bias != 0.0) and label != \"ideal\":\n",
    "        noise = np.random.normal(loc=0.0, scale=sigma, size=PP.shape)   \n",
    "        bias_vec = np.array([[bias], [bias], [bias]], dtype=float)      \n",
    "        PP = PP + noise + bias_vec\n",
    " \n",
    "    # Save to dictionary\n",
    "    transformed_sets[label] = {\n",
    "        \"P_original\": P,\n",
    "        \"P_transformed\": PP,\n",
    "        \"theta\": theta,\n",
    "        \"phi\": phi\n",
    "    }\n",
    "\n",
    "    # Print first 3 transformed coordinates\n",
    "    print(\"\\033[1mTransformed coordinates (first 3 points):\\033[0m\")\n",
    "    print(PP[:, :3].T)\n",
    "\n",
    "# --- Print matrix and angle information ---\n",
    "print(\"\\033[1m\\nRotation around X-axis (radians):\\033[0m\", rx)\n",
    "print(\"\\033[1m\\nRotation around Y-axis (radians):\\033[0m\", ry)\n",
    "print(\"\\033[1m\\nRotation around Z-axis (radians):\\033[0m\", rz)\n",
    "\n",
    "print(\"\\033[1m\\nSymbolic rotation matrix:\\033[0m\")\n",
    "print(sp.pretty(R_sym, use_unicode=False, wrap_line=False))\n",
    "\n",
    "print(\"\\033[1m\\nNumerical rotation matrix for configured angles:\\033[0m\")\n",
    "print(sp.pretty(R_numerical.evalf(), use_unicode=False, wrap_line=False))\n",
    "\n",
    "print(\"\\033[1m\\nParametric matrix R:\\033[0m\")\n",
    "sp.pprint(R_sym_symbols, use_unicode=False)\n",
    "\n",
    "print(\"\\033[1m\\nCoefficients of rotation matrix: a1, a2, ..., c3\\033[0m\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9479a06f-7d35-4268-ab85-56a52def5a79",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkgreen; font-weight:bold\">Export to Excel – Fixed and Local Frames</span>\n",
    "\n",
    "At this stage, the generated coordinates (e.g., ideal, noisy, or geodetically distorted points)  \n",
    "are exported to `.xlsx` files for external analysis or use in downstream transformation algorithms.\n",
    "\n",
    "Each coordinate set is saved as a table with `X`, `Y`, and `Z` columns, optionally accompanied by point indices.\n",
    "\n",
    "The export uses the **OpenPyXL** engine to ensure compatibility with spreadsheet software and preserves the structure of the point cloud.\n",
    "\n",
    "To change the output filenames or worksheet names, adjust the parameters in the code cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25517660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# Optional new code for more detailed export with metadata and angles\n",
    "# ====================================================================\n",
    "\n",
    "\n",
    "# === Export (Excel + JSON) ===\n",
    "export_dir = \"exports_excel\"\n",
    "os.makedirs(export_dir, exist_ok=True)\n",
    "\n",
    "def _angles_df(theta, phi):\n",
    "    \"\"\"Return a DataFrame with angles if available; otherwise an empty DataFrame.\"\"\"\n",
    "    if theta is None or phi is None:\n",
    "        return pd.DataFrame()\n",
    "    return pd.DataFrame({\"theta_rad\": np.asarray(theta), \"phi_rad\": np.asarray(phi)})\n",
    "\n",
    "# Helpful suffix: synthetic/pcd/csv\n",
    "src_tag = INPUT_CFG.get(\"source\", \"synthetic\").lower()\n",
    "\n",
    "for label, data in transformed_sets.items():\n",
    "    # Build DataFrames (ensure (N,3))\n",
    "    df_original   = pd.DataFrame(data[\"P_original\"].T,    columns=[\"X\", \"Y\", \"Z\"])\n",
    "    df_transformed= pd.DataFrame(data[\"P_transformed\"].T, columns=[\"X\", \"Y\", \"Z\"])\n",
    "    df_angles     = _angles_df(data.get(\"theta\"), data.get(\"phi\"))\n",
    "\n",
    "    # Metadata sheet – minimal but useful\n",
    "    meta_rows = [\n",
    "        (\"input_source\", src_tag),\n",
    "        (\"input_path\", INPUT_CFG.get(\"path\", \"\")),\n",
    "        (\"n_points\", len(df_original)),\n",
    "        (\"roll_grad\",  config[\"roll\"]),\n",
    "        (\"pitch_grad\", config[\"pitch\"]),\n",
    "        (\"yaw_grad\",   config[\"yaw\"]),\n",
    "        (\"dx_m\", config[\"dx\"]), (\"dy_m\", config[\"dy\"]), (\"dz_m\", config[\"dz\"]),\n",
    "        (\"gaussian_std_m\", config.get(\"gaussian_std\", 0.0)),\n",
    "        (\"bias_m\", config.get(\"bias\", 0.0)),\n",
    "    ]\n",
    "    df_meta = pd.DataFrame(meta_rows, columns=[\"key\", \"value\"])\n",
    "\n",
    "    # File name: <source>_<label>_coordinates.xlsx\n",
    "    fname = f\"{src_tag}_{label}_coordinates.xlsx\"\n",
    "    file_path = os.path.join(export_dir, fname)\n",
    "\n",
    "    with pd.ExcelWriter(file_path, engine=\"openpyxl\") as writer:\n",
    "        df_original.to_excel(writer, index=False, sheet_name=\"Original_Global\")\n",
    "        df_transformed.to_excel(writer, index=False, sheet_name=\"Transformed_Local\")\n",
    "        if not df_angles.empty:\n",
    "            df_angles.to_excel(writer, index=False, sheet_name=\"Angles_(rad)\")\n",
    "        df_meta.to_excel(writer, index=False, sheet_name=\"Metadata\")\n",
    "\n",
    "# Export combined configuration as JSON (config + INPUT_CFG)\n",
    "config_path = os.path.join(export_dir, \"config_used.json\")\n",
    "with open(config_path, \"w\") as f:\n",
    "    json.dump({\"config\": config, \"input_cfg\": INPUT_CFG}, f, indent=4)\n",
    "\n",
    "# List exported files for convenience\n",
    "output_files = sorted(os.listdir(export_dir))\n",
    "output_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb66556b-7aa8-4c67-897c-f35610efc439",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkgreen; font-weight:bold\">Visualization and Statistics – Synthetic and Real Inputs</span>\n",
    "\n",
    "This section provides two complementary views:\n",
    "\n",
    "**A. Global vs Body (illustrative geometry)**  \n",
    "Side-by-side 3D plots show the same points in the global (original) and body (transformed) frames.  \n",
    "This view is **not an uncertainty plot**; it illustrates the rigid-body transformation (R, t) applied to the data.  \n",
    "Works for both *synthetic* and *real (PCD/CSV)* inputs.\n",
    "\n",
    "**B. Structure & Displacement summary**  \n",
    "2D projections (XY/XZ/YZ), a PCA density view, and displacement statistics.  \n",
    "By default we show **rigid displacement** between global and body coordinates (|Δ| = ‖P_body − P_global‖).  \n",
    "Optionally, this block can switch to **noise-only** diagnostics (|Δ| between a *noisy* and a *clean* body-frame set),  \n",
    "if both variants are available.\n",
    "\n",
    "All figures are saved as **vector graphics (SVG)** for publication-quality output.  \n",
    "Rendering options (marker size, transparency, grid) can be adjusted inline in the plotting helpers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3584c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Visualization: Global vs. Body Frame (illustrative) ===\n",
    "# Purpose:\n",
    "#   - Visual check of spatial structure before/after the rigid-body transform (R, t).\n",
    "#   - This is NOT an uncertainty plot; it does not show noise, only geometry.\n",
    "# Works with:\n",
    "#   - Synthetic sets (e.g., \"ideal\").\n",
    "#   - Real input (\"real_input\") if loaded via INPUT_CFG.\n",
    "# Output:\n",
    "#   - Side-by-side 3D scatter + reference wireframe sphere.\n",
    "#   - Saved as SVG in exports_img/.\n",
    "    \n",
    "os.makedirs(\"exports_img\", exist_ok=True)\n",
    "\n",
    "def plot_on_ax(ax, points, title, color):\n",
    "    \"\"\"\n",
    "    Scatter 3D points plus a matching-radius wireframe sphere on the given Axes3D.\n",
    "    \"\"\"\n",
    "    x, y, z = points\n",
    "    r = np.max(np.linalg.norm(points, axis=0))  # approximate radius\n",
    "    u = np.linspace(0, 2*np.pi, 40)\n",
    "    v = np.linspace(0, np.pi, 40)\n",
    "    xw = r * np.outer(np.cos(u), np.sin(v))\n",
    "    yw = r * np.outer(np.sin(u), np.sin(v))\n",
    "    zw = r * np.outer(np.ones_like(u), np.cos(v))\n",
    "    ax.scatter(x, y, z, s=6, alpha=0.7, color=color)\n",
    "    ax.plot_wireframe(xw, yw, zw, color=\"gray\", linewidth=0.6, alpha=0.3)\n",
    "    ax.set_title(title, pad=10)\n",
    "    ax.set_xlabel(\"X [m]\")\n",
    "    ax.set_ylabel(\"Y [m]\")\n",
    "    ax.set_zlabel(\"Z [m]\")\n",
    "    ax.set_box_aspect((1,1,1))\n",
    "\n",
    "# Select which labels to plot\n",
    "labels_to_plot = [\"ideal\"]  # default synthetic\n",
    "if \"real_input\" in transformed_sets:\n",
    "    labels_to_plot.insert(0, \"real_input\")  # show real-data first if present\n",
    "\n",
    "for lbl in labels_to_plot:\n",
    "    fig = plt.figure(figsize=(14, 6))\n",
    "    src = INPUT_CFG.get(\"source\", \"synthetic\").lower()\n",
    "    npts = transformed_sets[lbl][\"P_original\"].shape[1]\n",
    "\n",
    "    # Global/original\n",
    "    ax1 = fig.add_subplot(1,2,1, projection=\"3d\")\n",
    "    plot_on_ax(ax1,\n",
    "               transformed_sets[lbl][\"P_original\"],\n",
    "               title=f\"{lbl} – Original (Global Frame)\\n{src}, N={npts}\",\n",
    "               color=\"royalblue\")\n",
    "\n",
    "    # Transformed/body\n",
    "    ax2 = fig.add_subplot(1,2,2, projection=\"3d\")\n",
    "    plot_on_ax(ax2,\n",
    "               transformed_sets[lbl][\"P_transformed\"],\n",
    "               title=f\"{lbl} – Transformed (Body Frame)\",\n",
    "               color=\"darkred\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # save as vector format (publication quality)\n",
    "    out_path = os.path.join(\"exports_img\", f\"comparison_{lbl}.svg\")\n",
    "    plt.savefig(out_path, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Saved: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fad7c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Alternative visualizations: structure & displacement ===\n",
    "# Purpose:\n",
    "#   - Summarize the point-cloud structure (2D projections, PCA) and displacement statistics.\n",
    "# Default behavior (VIS_MODE = \"rigid\"):\n",
    "#   - Displacement is rigid: Δ = P_body - P_global (illustrates the net effect of R, t).\n",
    "# Optional behavior (VIS_MODE = \"noise-only\"):\n",
    "#   - If you have a clean/noisy pair in the body frame (e.g., \"ideal\" vs \"with_geodetic_distortion\"\n",
    "#     or \"real_input_clean\" vs \"real_input_noisy\"), set VIS_MODE=\"noise-only\" and provide labels below.\n",
    "#   - Then Δ = P_body_noisy - P_body_clean (true uncertainty/noise diagnostics).\n",
    "# Outputs:\n",
    "#   - 2D projections (XY/XZ/YZ) with equal aspect.\n",
    "#   - PCA-based density (hexbin).\n",
    "#   - Histograms of Δ and |Δ|, and |Δ| vs range r (EDM-friendly).\n",
    "#   - All figures saved as SVG in exports_img/.\n",
    "\n",
    "os.makedirs(\"exports_img\", exist_ok=True)\n",
    "\n",
    "def _as_Nx3(P_3xN):\n",
    "    return P_3xN.T if P_3xN.shape[0] == 3 else P_3xN\n",
    "\n",
    "def _equal_axes(ax):\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "# --- NEW: choose visualization mode ---\n",
    "VIS_MODE = \"rigid\"  # \"rigid\" | \"noise-only\"\n",
    "NOISE_CLEAN_LABEL = \"ideal\"                 # e.g., \"ideal\" or \"real_input_clean\"\n",
    "NOISE_NOISY_LABEL = \"with_geodetic_distortion\"   # e.g., \"with_noise\" or \"real_input_noisy\"\n",
    "\n",
    "# --- Select base label (used for titles and structure plots) ---\n",
    "label = \"real_input\" if \"real_input\" in transformed_sets else \"ideal\"\n",
    "src_tag = INPUT_CFG.get(\"source\", \"synthetic\").lower()\n",
    "\n",
    "# --- Build P0, P1 depending on mode ---\n",
    "if VIS_MODE == \"noise-only\" and NOISE_CLEAN_LABEL in transformed_sets and NOISE_NOISY_LABEL in transformed_sets:\n",
    "    # noise-only in BODY frame\n",
    "    P0 = _as_Nx3(transformed_sets[NOISE_CLEAN_LABEL][\"P_transformed\"])   # (N,3) clean body\n",
    "    P1 = _as_Nx3(transformed_sets[NOISE_NOISY_LABEL][\"P_transformed\"])   # (N,3) noisy body\n",
    "    label_for_titles = f\"{NOISE_CLEAN_LABEL} vs {NOISE_NOISY_LABEL}\"\n",
    "else:\n",
    "    # rigid displacement: GLOBAL vs BODY\n",
    "    P0 = _as_Nx3(transformed_sets[label][\"P_original\"])      # (N,3) global\n",
    "    P1 = _as_Nx3(transformed_sets[label][\"P_transformed\"])   # (N,3) body\n",
    "    label_for_titles = f\"{label} (rigid)\"\n",
    "\n",
    "# 2) 2D projections (XY, XZ, YZ)\n",
    "projs = [(\"XY\", 0, 1), (\"XZ\", 0, 2), (\"YZ\", 1, 2)]\n",
    "for name, i, j in projs:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    for ax, P, ttl in [(axes[0], P0, f\"{label_for_titles} – Left ({name})\"),\n",
    "                       (axes[1], P1, f\"{label_for_titles} – Right ({name})\")]:\n",
    "        ax.scatter(P[:, i], P[:, j], s=2, alpha=0.5)\n",
    "        ax.set_xlabel(f\"{['X','Y','Z'][i]} [m]\")\n",
    "        ax.set_ylabel(f\"{['X','Y','Z'][j]} [m]\")\n",
    "        ax.set_title(ttl); _equal_axes(ax); ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    outp = os.path.join(\"exports_img\", f\"proj_{name.lower()}_{label}_{src_tag}_{VIS_MODE}.svg\")\n",
    "    plt.savefig(outp, bbox_inches=\"tight\"); plt.show(); print(\"Saved:\", outp)\n",
    "\n",
    "# 3) PCA density view (same basis for left/right)\n",
    "X = P0 - P0.mean(axis=0, keepdims=True)\n",
    "U, S, Vt = np.linalg.svd(X, full_matrices=False)\n",
    "P0_pca2 = X @ Vt.T[:, :2]\n",
    "Y = P1 - P1.mean(axis=0, keepdims=True)\n",
    "P1_pca2 = Y @ Vt.T[:, :2]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "for ax, P2, ttl in [(axes[0], P0_pca2, f\"{label_for_titles} – Left (PCA)\"),\n",
    "                    (axes[1], P1_pca2, f\"{label_for_titles} – Right (PCA)\")]:\n",
    "    hb = ax.hexbin(P2[:,0], P2[:,1], gridsize=80, bins='log')\n",
    "    ax.set_xlabel(\"PC1 [arb.]\"); ax.set_ylabel(\"PC2 [arb.]\")\n",
    "    ax.set_title(ttl); ax.grid(True, alpha=0.2)\n",
    "plt.tight_layout()\n",
    "outp = os.path.join(\"exports_img\", f\"pca_hexbin_{label}_{src_tag}_{VIS_MODE}.svg\")\n",
    "plt.savefig(outp, bbox_inches=\"tight\"); plt.show(); print(\"Saved:\", outp)\n",
    "\n",
    "# 4) Displacement statistics\n",
    "disp = np.linalg.norm(P1 - P0, axis=1)\n",
    "fig = plt.figure(figsize=(6,4))\n",
    "plt.hist(disp, bins=60)\n",
    "plt.xlabel(\"|Δ| [m]\"); plt.ylabel(\"count\")\n",
    "plt.title(f\"Displacement magnitude – {label_for_titles} ({src_tag}, {VIS_MODE})\")\n",
    "outp = os.path.join(\"exports_img\", f\"disp_hist_{label}_{src_tag}_{VIS_MODE}.svg\")\n",
    "plt.savefig(outp, bbox_inches=\"tight\"); plt.show(); print(\"Saved:\", outp)\n",
    "\n",
    "fig = plt.figure(figsize=(6,4))\n",
    "for k, axlbl in enumerate([\"ΔX\",\"ΔY\",\"ΔZ\"]):\n",
    "    plt.hist(P1[:,k]-P0[:,k], bins=60, histtype='step', label=axlbl)\n",
    "plt.xlabel(\"Δ [m]\"); plt.ylabel(\"count\"); plt.legend()\n",
    "plt.title(f\"Per-axis displacements – {label_for_titles} ({src_tag}, {VIS_MODE})\")\n",
    "outp = os.path.join(\"exports_img\", f\"disp_axes_{label}_{src_tag}_{VIS_MODE}.svg\")\n",
    "plt.savefig(outp, bbox_inches=\"tight\"); plt.show(); print(\"Saved:\", outp)\n",
    "\n",
    "# 5) |Δ| vs range r (EDM-friendly)\n",
    "r = np.linalg.norm(P1 if VIS_MODE==\"rigid\" else P0, axis=1)  # for noise-only, range of the clean body set\n",
    "fig = plt.figure(figsize=(6,4))\n",
    "plt.scatter(r, disp, s=3, alpha=0.3)\n",
    "plt.xlabel(\"range r [m]\"); plt.ylabel(\"|Δ| [m]\")\n",
    "plt.title(f\"|Δ| vs r – {label_for_titles} ({src_tag}, {VIS_MODE})\")\n",
    "plt.tight_layout()\n",
    "outp = os.path.join(\"exports_img\", f\"disp_vs_r_{label}_{src_tag}_{VIS_MODE}.svg\")\n",
    "plt.savefig(outp, bbox_inches=\"tight\"); plt.show(); print(\"Saved:\", outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ce875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Noise-only diagnostics in the body frame (EDM/Gaussian) ===\n",
    "# Compare noisy vs. noiseless transform to isolate error model effects.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.makedirs(\"exports_img\", exist_ok=True)\n",
    "\n",
    "# We assume you have at least the \"ideal\" and one noisy set, e.g. \"with_geodetic_distortion\"\n",
    "if \"ideal\" in transformed_sets and \"with_geodetic_distortion\" in transformed_sets:\n",
    "    P_body_clean = transformed_sets[\"ideal\"][\"P_transformed\"].T      # (N,3)\n",
    "    P_body_noisy = transformed_sets[\"with_geodetic_distortion\"][\"P_transformed\"].T  # (N,3)\n",
    "\n",
    "    disp_noise = np.linalg.norm(P_body_noisy - P_body_clean, axis=1)   # |Δ_noise|\n",
    "    r_body     = np.linalg.norm(P_body_clean, axis=1)                  # range after R,t\n",
    "\n",
    "    # 1) Histogram |Δ| from noise only\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.hist(disp_noise, bins=60)\n",
    "    plt.xlabel(\"|Δ| [m]\"); plt.ylabel(\"count\")\n",
    "    plt.title(\"Noise-only displacement (body frame)\\nwith_geodetic_distortion vs ideal\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"exports_img/noise_only_hist.svg\", bbox_inches=\"tight\"); plt.show()\n",
    "\n",
    "    # 2) |Δ| vs r (EDM should give ~linear trend: |Δ| ≈ |a + b r|)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.scatter(r_body, disp_noise, s=3, alpha=0.3)\n",
    "    plt.xlabel(\"range r (body) [m]\"); plt.ylabel(\"|Δ| [m]\")\n",
    "    plt.title(\"|Δ| vs r – noise-only (body frame)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"exports_img/noise_only_disp_vs_r.svg\", bbox_inches=\"tight\"); plt.show()\n",
    "\n",
    "    # Optional: overlay least-squares line for visual guidance\n",
    "    A = np.vstack([r_body, np.ones_like(r_body)]).T\n",
    "    k, c = np.linalg.lstsq(A, disp_noise, rcond=None)[0]  # disp ≈ k*r + c\n",
    "    print(f\"Least-squares fit: |Δ| ≈ {c:.6f} + {k:.6e}·r   (compare to EDM a, b)\")\n",
    "else:\n",
    "    print(\"Need both 'ideal' and 'with_geodetic_distortion' in transformed_sets for noise-only plots.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10559fa4",
   "metadata": {},
   "source": [
    "### <span style=\"color:green; font-weight:bold\">Coordinate Uncertainty – Noise and Distortion Only</span>\n",
    "\n",
    "This section isolates the uncertainty component by comparing **ideal transformed points** \n",
    "(without any perturbations) against their **noisy/distorted counterparts** after the same \n",
    "rigid-body transformation (R, t). \n",
    "\n",
    "Key points:\n",
    "- The rigid transformation (rotation + translation) is applied identically to both sets, \n",
    "  so only **random noise and geodetic distortion effects** remain in the differences.\n",
    "- The plots show:\n",
    "  - Error bars in the XY, XZ, and YZ planes,\n",
    "  - Histograms of ΔX and ΔY,\n",
    "  - A 2D histogram of ΔX vs ΔY.\n",
    "- This allows for a direct visualization of **measurement noise impact** independent \n",
    "  of alignment or frame transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2b01f7-92bf-455b-8550-a86ae852ffcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Helpers for uncertainty analysis (works for synthetic and real data) ===\n",
    "# 1) add_real_noise_pair: create \"real_input_clean\" / \"real_input_noisy\" from an existing \"real_input\"\n",
    "# 2) noise_only_residuals: return (P_clean, P_noisy, Δx, Δy, Δz, |Δ|, range_clean)\n",
    "\n",
    "def add_real_noise_pair(transformed_sets, base_label=\"real_input\",\n",
    "                        gaussian_std=0.01, bias=0.0, edm=None, seed=42):\n",
    "    \"\"\"\n",
    "    Create 'base_label_clean' and 'base_label_noisy' entries in transformed_sets.\n",
    "\n",
    "    Noise model:\n",
    "      - Gaussian XYZ in the body frame: N(0, gaussian_std) + bias (vector of identical bias per axis)\n",
    "      - Optional EDM range perturbation: r' = r + a + b*r  with edm=(a [m], b [unitless])\n",
    "        (applied after Gaussian+bias; directions are preserved)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    transformed_sets : dict  (must contain base_label with keys \"P_transformed\" and \"P_original\")\n",
    "    base_label       : str   (\"real_input\" by default)\n",
    "    gaussian_std     : float [m]\n",
    "    bias             : float [m]\n",
    "    edm              : tuple (a, b)  or None\n",
    "    seed             : int\n",
    "    \"\"\"\n",
    "    assert base_label in transformed_sets, f\"Missing '{base_label}' in transformed_sets.\"\n",
    "\n",
    "    P0 = transformed_sets[base_label][\"P_original\"]         # (3, N) global (kept for completeness)\n",
    "    P1 = transformed_sets[base_label][\"P_transformed\"]      # (3, N) body (clean baseline)\n",
    "    theta = transformed_sets[base_label].get(\"theta\", None)\n",
    "    phi   = transformed_sets[base_label].get(\"phi\", None)\n",
    "\n",
    "    # Clean copy (no additional noise)\n",
    "    transformed_sets[f\"{base_label}_clean\"] = {\n",
    "        \"P_original\": P0.copy(),\n",
    "        \"P_transformed\": P1.copy(),\n",
    "        \"theta\": theta, \"phi\": phi,\n",
    "    }\n",
    "\n",
    "    # Noisy copy\n",
    "    rng = np.random.default_rng(seed)\n",
    "    Pn = P1.copy()\n",
    "\n",
    "    if gaussian_std != 0.0 or bias != 0.0:\n",
    "        noise = rng.normal(0.0, gaussian_std, size=Pn.shape)\n",
    "        bias_vec = np.array([[bias], [bias], [bias]], dtype=float)\n",
    "        Pn = Pn + noise + bias_vec\n",
    "\n",
    "    if edm is not None:\n",
    "        a, b = edm\n",
    "        r  = np.linalg.norm(Pn, axis=0, keepdims=True)             # (1, N)\n",
    "        u  = Pn / np.maximum(r, 1e-12)                             # unit directions\n",
    "        r2 = r + a + b * r\n",
    "        Pn = u * r2\n",
    "\n",
    "    transformed_sets[f\"{base_label}_noisy\"] = {\n",
    "        \"P_original\": P0.copy(),\n",
    "        \"P_transformed\": Pn,\n",
    "        \"theta\": theta, \"phi\": phi,\n",
    "    }\n",
    "\n",
    "def noise_only_residuals(transformed_sets, clean_label, noisy_label):\n",
    "    \"\"\"\n",
    "    Compute noise-only residuals between two body-frame sets:\n",
    "        Δ = P_body(noisy) - P_body(clean)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Pc   : (N, 3) clean body points\n",
    "    Pn   : (N, 3) noisy body points\n",
    "    dx,dy,dz : 1D arrays, residuals per axis [m]\n",
    "    dmag     : 1D array, |Δ| [m]\n",
    "    r_clean  : 1D array, range of clean points [m]\n",
    "    \"\"\"\n",
    "    Pc = transformed_sets[clean_label][\"P_transformed\"].T   # (N, 3)\n",
    "    Pn = transformed_sets[noisy_label][\"P_transformed\"].T   # (N, 3)\n",
    "    d  = Pn - Pc\n",
    "    r  = np.linalg.norm(Pc, axis=1)\n",
    "    return Pc, Pn, d[:, 0], d[:, 1], d[:, 2], np.linalg.norm(d, axis=1), r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c1239d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Coordinate Uncertainty (noise-only, Body frame) ===\n",
    "# Purpose:\n",
    "#   Isolate the effect of measurement noise / EDM distortion by comparing a CLEAN\n",
    "#   body-frame set against a NOISY body-frame set produced with the *same* rigid\n",
    "#   transformation (R, t). The difference (Δ) removes the influence of rotation/translation\n",
    "#   and leaves only the uncertainty component.\n",
    "#\n",
    "# Works with:\n",
    "#   - Synthetic:        CLEAN=\"ideal\"  vs NOISY=\"with_geodetic_distortion\" (or \"with_noise\")\n",
    "#   - Real data (PCD/CSV) after pairing: CLEAN=\"real_input_clean\" vs NOISY=\"real_input_noisy\"\n",
    "#\n",
    "# Output:\n",
    "#   - XY/XZ/YZ scatter with ±|Δ| error bars\n",
    "#   - Histograms of ΔX and ΔY\n",
    "#   - 2D histogram (ΔX vs ΔY)\n",
    "#   - All saved as SVG to exports_img/\n",
    "\n",
    "os.makedirs(\"exports_img\", exist_ok=True)\n",
    "\n",
    "# --- Choose which pair you want to analyze (labels must exist in transformed_sets) ---\n",
    "CLEAN_LABEL = \"ideal\"                      # e.g. \"ideal\" or \"real_input_clean\"\n",
    "NOISY_LABEL = \"with_geodetic_distortion\"  # e.g. \"with_noise\" or \"real_input_noisy\"\n",
    "\n",
    "if CLEAN_LABEL in transformed_sets and NOISY_LABEL in transformed_sets:\n",
    "    # Body-frame coordinates are stored as (3, N); convert to (N, 3) for convenience.\n",
    "    P_body_clean = transformed_sets[CLEAN_LABEL][\"P_transformed\"].T   # (N, 3)\n",
    "    P_body_noisy = transformed_sets[NOISY_LABEL][\"P_transformed\"].T   # (N, 3)\n",
    "\n",
    "    # Noise-only residuals: Δ = noisy - clean  (removes the rigid-body component)\n",
    "    d = P_body_noisy - P_body_clean\n",
    "    dx, dy, dz = d[:, 0], d[:, 1], d[:, 2]\n",
    "    err_mag = np.linalg.norm(d, axis=1)\n",
    "\n",
    "    # Positions (clean body) for plotting error bars\n",
    "    Xb, Yb, Zb = P_body_clean[:, 0], P_body_clean[:, 1], P_body_clean[:, 2]\n",
    "\n",
    "    # --- Quick stats (useful in the console / notebook log) ---\n",
    "    print(f\"[uncertainty] Pair: {CLEAN_LABEL} vs {NOISY_LABEL}\")\n",
    "    print(f\"  N = {len(err_mag)}\")\n",
    "    print(f\"  mean(ΔX, ΔY, ΔZ) = ({dx.mean():.4e}, {dy.mean():.4e}, {dz.mean():.4e}) m\")\n",
    "    print(f\"  std(ΔX, ΔY, ΔZ)  = ({dx.std(ddof=1):.4e}, {dy.std(ddof=1):.4e}, {dz.std(ddof=1):.4e}) m\")\n",
    "    print(f\"  RMSE(|Δ|) = {np.sqrt((err_mag**2).mean()):.4e} m\")\n",
    "\n",
    "    # --- Plot grid: 2 rows × 3 columns ---\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(14, 8))\n",
    "    fig.suptitle('Coordinate Uncertainty Summary (noise-only, Body frame)', fontsize=14, fontweight='bold')\n",
    "\n",
    "    # a) X–Y with ±|Δ|\n",
    "    ax = axes[0, 0]\n",
    "    ax.errorbar(Xb, Yb, xerr=np.abs(dx), yerr=np.abs(dy),\n",
    "                fmt='o', ms=3, color='darkred', ecolor='slategray', alpha=0.7, label='±|Δ|')\n",
    "    ax.set_xlabel('X [m]'); ax.set_ylabel('Y [m]')\n",
    "    ax.set_title('X–Y with Uncertainty'); ax.legend()\n",
    "    ax.set_aspect('equal', adjustable='box'); ax.grid(True, alpha=0.25)\n",
    "\n",
    "    # b) X–Z with ±|Δ|\n",
    "    ax = axes[0, 1]\n",
    "    ax.errorbar(Xb, Zb, xerr=np.abs(dx), yerr=np.abs(dz),\n",
    "                fmt='o', ms=3, color='darkred', ecolor='slategray', alpha=0.7, label='±|Δ|')\n",
    "    ax.set_xlabel('X [m]'); ax.set_ylabel('Z [m]')\n",
    "    ax.set_title('X–Z with Uncertainty'); ax.legend()\n",
    "    ax.set_aspect('equal', adjustable='box'); ax.grid(True, alpha=0.25)\n",
    "\n",
    "    # c) Y–Z with ±|Δ|\n",
    "    ax = axes[0, 2]\n",
    "    ax.errorbar(Yb, Zb, xerr=np.abs(dy), yerr=np.abs(dz),\n",
    "                fmt='o', ms=3, color='darkred', ecolor='slategray', alpha=0.7, label='±|Δ|')\n",
    "    ax.set_xlabel('Y [m]'); ax.set_ylabel('Z [m]')\n",
    "    ax.set_title('Y–Z with Uncertainty'); ax.legend()\n",
    "    ax.set_aspect('equal', adjustable='box'); ax.grid(True, alpha=0.25)\n",
    "\n",
    "    # d) Histogram of ΔX\n",
    "    ax = axes[1, 0]\n",
    "    ax.hist(dx, bins=40, color='steelblue', alpha=0.85, edgecolor='black')\n",
    "    ax.set_xlabel('ΔX [m]'); ax.set_ylabel('Count')\n",
    "    ax.set_title('Histogram of ΔX')\n",
    "\n",
    "    # e) Histogram of ΔY\n",
    "    ax = axes[1, 1]\n",
    "    ax.hist(dy, bins=40, color='steelblue', alpha=0.85, edgecolor='black')\n",
    "    ax.set_xlabel('ΔY [m]'); ax.set_ylabel('Count')\n",
    "    ax.set_title('Histogram of ΔY')\n",
    "\n",
    "    # f) 2D histogram (ΔX vs ΔY) — helps to reveal potential correlation between axes\n",
    "    ax = axes[1, 2]\n",
    "    h = ax.hist2d(dx, dy, bins=40, cmap='viridis', cmin=1)\n",
    "    ax.set_xlabel('ΔX [m]'); ax.set_ylabel('ΔY [m]')\n",
    "    ax.set_title('2D Histogram: ΔX vs ΔY')\n",
    "    plt.colorbar(h[3], ax=ax, label='Count')\n",
    "\n",
    "    # Layout + save\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    out_name = f\"uncertainty_noise_only_body_{CLEAN_LABEL}_vs_{NOISY_LABEL}.svg\"\n",
    "    out_path = os.path.join(\"exports_img\", out_name)\n",
    "    plt.savefig(out_path, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(\"Saved:\", out_path)\n",
    "\n",
    "else:\n",
    "    # Helpful guidance if labels are not present\n",
    "    print(\"Uncertainty view requires two body-frame variants in `transformed_sets`:\")\n",
    "    print(f\"  - CLEAN label (found: {CLEAN_LABEL in transformed_sets}): {CLEAN_LABEL}\")\n",
    "    print(f\"  - NOISY label (found: {NOISY_LABEL in transformed_sets}): {NOISY_LABEL}\")\n",
    "    print(\"Tips:\")\n",
    "    print(\"  • For synthetic data, generate 'ideal' and a noisy variant \"\n",
    "          \"('with_geodetic_distortion' or 'with_noise').\")\n",
    "    print(\"  • For real data, first create a pair via add_real_noise_pair(\"\n",
    "          \"base_label='real_input', gaussian_std=..., edm=(A, B*1e-6)).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2363d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = float(config.get(\"gaussian_std\", 0.0))\n",
    "bias  = float(config.get(\"bias\", 0.0))\n",
    "theory_mag = np.sqrt(3)*sigma  # bez EDM i bias\n",
    "print(f\"Expected |Δ| from Gaussian only: ~{theory_mag:.4f} m \"\n",
    "      f\"(observed RMSE |Δ| ~{np.sqrt((err_mag**2).mean()):.4f} m)\")\n",
    "print(f\"Configured bias: {bias:.4f} m (means: {dx.mean():.4f}, {dy.mean():.4f}, {dz.mean():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6badf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Coordinate Uncertainty – noise-only (Body frame) ===\n",
    "# Choose which pair to compare. For synthetic data you likely want:\n",
    "#   CLEAN_LABEL=\"ideal\", NOISY_LABEL=\"with_geodetic_distortion\" (or \"with_noise\")\n",
    "# For real data after add_real_noise_pair(...):\n",
    "#   CLEAN_LABEL=\"real_input_clean\", NOISY_LABEL=\"real_input_noisy\"\n",
    "\n",
    "os.makedirs(\"exports_img\", exist_ok=True)\n",
    "\n",
    "CLEAN_LABEL = \"ideal\"\n",
    "NOISY_LABEL = \"with_geodetic_distortion\"\n",
    "SAVE_PREFIX = f\"uncertainty_{CLEAN_LABEL}_vs_{NOISY_LABEL}\"\n",
    "\n",
    "if CLEAN_LABEL in transformed_sets and NOISY_LABEL in transformed_sets:\n",
    "    # Compute residuals\n",
    "    Pc, Pn, dx, dy, dz, dmag, r_clean = noise_only_residuals(\n",
    "        transformed_sets, CLEAN_LABEL, NOISY_LABEL\n",
    "    )\n",
    "\n",
    "    # --- Summary stats to console ---\n",
    "    import numpy as np\n",
    "    print(f\"[uncertainty] Pair: {CLEAN_LABEL} vs {NOISY_LABEL} | N={len(dmag)}\")\n",
    "    print(f\"  mean(ΔX,ΔY,ΔZ) = ({dx.mean():.4e}, {dy.mean():.4e}, {dz.mean():.4e}) m\")\n",
    "    print(f\"  std (ΔX,ΔY,ΔZ) = ({dx.std(ddof=1):.4e}, {dy.std(ddof=1):.4e}, {dz.std(ddof=1):.4e}) m\")\n",
    "    print(f\"  RMSE(|Δ|)      = {np.sqrt((dmag**2).mean()):.4e} m\")\n",
    "\n",
    "    # --- 1) Per-axis histograms ---\n",
    "    fig = plt.figure(figsize=(12, 4))\n",
    "    for k, (arr, title) in enumerate([(dx, \"ΔX\"), (dy, \"ΔY\"), (dz, \"ΔZ\")], start=1):\n",
    "        ax = fig.add_subplot(1, 3, k)\n",
    "        ax.hist(arr, bins=60, histtype=\"stepfilled\", alpha=0.85)\n",
    "        ax.set_xlabel(f\"{title} [m]\"); \n",
    "        ax.set_ylabel(\"count\" if k == 1 else \"\")\n",
    "        ax.set_title(title)\n",
    "        ax.grid(True, alpha=0.25)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"exports_img/{SAVE_PREFIX}_axes_hist.svg\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    # --- 2) Magnitude CDF (|Δ|) ---\n",
    "    x = np.sort(dmag); y = np.linspace(0, 1, len(x), endpoint=True)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel(\"|Δ| [m]\"); plt.ylabel(\"cumulative probability\")\n",
    "    plt.title(\"Empirical CDF of |Δ|\")\n",
    "    plt.grid(True, alpha=0.25)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"exports_img/{SAVE_PREFIX}_cdf.svg\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    # --- 3) 2D histogram ΔX vs ΔY (correlation check) ---\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    h = plt.hist2d(dx, dy, bins=40, cmap=\"viridis\", cmin=1)\n",
    "    plt.xlabel(\"ΔX [m]\"); plt.ylabel(\"ΔY [m]\")\n",
    "    plt.title(\"2D Histogram: ΔX vs ΔY\")\n",
    "    plt.colorbar(h[3], label=\"Count\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"exports_img/{SAVE_PREFIX}_dx_dy_2dhist.svg\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    # --- 4) Box–Whisker for ΔX, ΔY, ΔZ (noise-only) ---\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    ax.boxplot([dx, dy, dz], tick_labels=[r'$\\Delta X$', r'$\\Delta Y$', r'$\\Delta Z$'],\n",
    "               showfliers=True)\n",
    "    ax.set_ylabel(\"Error [m]\")\n",
    "    ax.set_title(\"Box–Whisker: Per-Axis Error Distribution (noise-only)\")\n",
    "    ax.grid(True, axis=\"y\", alpha=0.25)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"exports_img/{SAVE_PREFIX}_box_whisker.svg\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    # --- 5) |Δ| vs range r (good for EDM) ---\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.scatter(r_clean, dmag, s=6, alpha=0.35)\n",
    "    plt.xlabel(\"range r (clean body) [m]\"); plt.ylabel(\"|Δ| [m]\")\n",
    "    plt.title(\"|Δ| vs r\")\n",
    "    plt.grid(True, alpha=0.25)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"exports_img/{SAVE_PREFIX}_disp_vs_r.svg\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"Uncertainty analysis requires:\")\n",
    "    print(f\"  CLEAN_LABEL present? {CLEAN_LABEL in transformed_sets}  -> {CLEAN_LABEL}\")\n",
    "    print(f\"  NOISY_LABEL present? {NOISY_LABEL in transformed_sets}  -> {NOISY_LABEL}\")\n",
    "    print(\"Tip: for real data call add_real_noise_pair(...) first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac805460",
   "metadata": {},
   "source": [
    "**Real vs Synthetic note.**  \n",
    "The calls `add_real_noise_pair(...)` and plotting with labels `real_input_clean/noisy` are only relevant when a real dataset was loaded (i.e., `real_input` exists in `transformed_sets`).  \n",
    "The safe invocation block below:\n",
    "1) builds the real clean/noisy pair only if `real_input` is present,  \n",
    "2) otherwise falls back to the synthetic pair (`ideal` vs `with_geodetic_distortion` or `with_noise`),  \n",
    "3) and produces the same uncertainty plots in both cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147d3b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Helpers to build clean/noisy pairs and to compute noise-only residuals ===\n",
    "\n",
    "def add_real_noise_pair(transformed_sets, base_label=\"real_input\",\n",
    "                        gaussian_std=0.01, bias=0.0, edm=None, seed=42):\n",
    "    \"\"\"\n",
    "    Create 'real_input_clean' and 'real_input_noisy' in transformed_sets from an existing 'real_input'.\n",
    "    - gaussian_std [m], bias [m] are added in body frame to XYZ.\n",
    "    - edm = (a, b) adds range-only noise: r' = r + a + b*r (applied after Gaussian/bias).\n",
    "    \"\"\"\n",
    "    assert base_label in transformed_sets, f\"Missing base label '{base_label}' in transformed_sets.\"\n",
    "\n",
    "    P0 = transformed_sets[base_label][\"P_original\"]      # (3, N)\n",
    "    P1 = transformed_sets[base_label][\"P_transformed\"]   # (3, N)\n",
    "    theta = transformed_sets[base_label].get(\"theta\", None)\n",
    "    phi   = transformed_sets[base_label].get(\"phi\", None)\n",
    "\n",
    "    # CLEAN = copy without extra noise\n",
    "    transformed_sets[f\"{base_label}_clean\"] = {\n",
    "        \"P_original\":   P0.copy(),\n",
    "        \"P_transformed\": P1.copy(),\n",
    "        \"theta\": theta, \"phi\": phi\n",
    "    }\n",
    "\n",
    "    # NOISY = apply noise in body frame\n",
    "    rng = np.random.default_rng(seed)\n",
    "    Pn = P1.copy()\n",
    "\n",
    "    if gaussian_std != 0.0 or bias != 0.0:\n",
    "        noise = rng.normal(0.0, gaussian_std, size=Pn.shape)\n",
    "        bias_vec = np.array([[bias],[bias],[bias]], dtype=float)\n",
    "        Pn = Pn + noise + bias_vec\n",
    "\n",
    "    if edm is not None:\n",
    "        a, b = edm  # [m], [unitless]\n",
    "        r  = np.linalg.norm(Pn, axis=0, keepdims=True)          # (1, N)\n",
    "        u  = Pn / np.maximum(r, 1e-12)                          # directions\n",
    "        r2 = r + a + b * r\n",
    "        Pn = u * r2\n",
    "\n",
    "    transformed_sets[f\"{base_label}_noisy\"] = {\n",
    "        \"P_original\":   P0.copy(),\n",
    "        \"P_transformed\": Pn,\n",
    "        \"theta\": theta, \"phi\": phi\n",
    "    }\n",
    "\n",
    "def noise_only_residuals(transformed_sets, clean_label, noisy_label):\n",
    "    \"\"\"Return (P_clean, P_noisy, Δx, Δy, Δz, |Δ|, range_clean).\"\"\"\n",
    "    Pc = transformed_sets[clean_label][\"P_transformed\"].T   # (N,3)\n",
    "    Pn = transformed_sets[noisy_label][\"P_transformed\"].T   # (N,3)\n",
    "    d  = Pn - Pc\n",
    "    r  = np.linalg.norm(Pc, axis=1)\n",
    "    return Pc, Pn, d[:,0], d[:,1], d[:,2], np.linalg.norm(d, axis=1), r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1ae1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Universal noise-only plotting suite (works for synthetic and real) ===\n",
    "\n",
    "\n",
    "def plot_uncertainty_suite(transformed_sets, clean_label, noisy_label,\n",
    "                           prefix=\"uncertainty\", subsample=None, seed=42):\n",
    "    \"\"\"\n",
    "    Produce: per-axis hist, magnitude CDF, QQ for ΔX, |Δ| vs r (EDM), and a light 2D projection.\n",
    "    Saves SVGs to exports_img/ with given prefix.\n",
    "    \"\"\"\n",
    "    Pc, Pn, dx, dy, dz, dmag, r = noise_only_residuals(transformed_sets, clean_label, noisy_label)\n",
    "\n",
    "    if not _HAS_SCIPY:\n",
    "        print(\"[info] SciPy not found → skipping Q–Q.\")\n",
    "\n",
    "    # Optional subsampling for dense clouds\n",
    "    if subsample:\n",
    "        rng = np.random.default_rng(seed)\n",
    "        idx = rng.choice(len(dmag), size=min(subsample, len(dmag)), replace=False)\n",
    "        Pc, dx, dy, dz, dmag, r = Pc[idx], dx[idx], dy[idx], dz[idx], dmag[idx], r[idx]\n",
    "\n",
    "    tag = f\"{prefix}_{clean_label}_vs_{noisy_label}\"\n",
    "\n",
    "    # 1) Per-axis histograms\n",
    "    plt.figure(figsize=(10,4))\n",
    "    for k,(arr,lbl) in enumerate([(dx,\"ΔX [m]\"), (dy,\"ΔY [m]\"), (dz,\"ΔZ [m]\")], start=1):\n",
    "        plt.subplot(1,3,k); plt.hist(arr, bins=60, histtype='stepfilled', alpha=0.8)\n",
    "        plt.xlabel(lbl); plt.ylabel(\"count\" if k==1 else \"\"); \n",
    "        plt.title(lbl.replace(\"[m]\",\"\"))\n",
    "    plt.tight_layout(); plt.savefig(f\"exports_img/{tag}_axes_hist.svg\", bbox_inches=\"tight\"); plt.show()\n",
    "\n",
    "    # 2) Magnitude CDF\n",
    "    x = np.sort(dmag); y = np.linspace(0,1,len(x),endpoint=True)\n",
    "    plt.figure(figsize=(6,4)); plt.plot(x,y)\n",
    "    plt.xlabel(\"|Δ| [m]\"); plt.ylabel(\"cumulative probability\"); \n",
    "    plt.title(\"Empirical CDF of |Δ|\"); \n",
    "    plt.tight_layout(); plt.savefig(f\"exports_img/{tag}_cdf.svg\", bbox_inches=\"tight\"); plt.show()\n",
    "\n",
    "    # 3) Q-Q for ΔX (Gaussian check)\n",
    "    try:\n",
    "        import scipy.stats as st\n",
    "        z = (dx - dx.mean()) / (dx.std(ddof=1)+1e-12)\n",
    "\n",
    "        theo_q, ordered = st.probplot(z, dist=\"norm\", fit=False)\n",
    "\n",
    "        plt.figure(figsize=(6,4))\n",
    "        plt.scatter(theo_q, ordered, s=10)\n",
    "        # 45° reference line\n",
    "        lim = max(abs(ordered.min()), abs(ordered.max()), abs(theo_q).max())\n",
    "        plt.plot([-lim, lim], [-lim, lim], 'r-')\n",
    "        plt.xlabel(\"Theoretical quantiles\"); plt.ylabel(\"Ordered values\")\n",
    "        plt.title(\"Q–Q Plot: ΔX vs Normal\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"exports_img/{tag}_qq_dx.svg\", bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(\"Skipping Q–Q (scipy not installed?):\", e)\n",
    "        \n",
    "    # 4) |Δ| vs range r (linear-ish if EDM dominates)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.scatter(r, dmag, s=5, alpha=0.4)\n",
    "    plt.xlabel(\"range r (body) [m]\"); plt.ylabel(\"|Δ| [m]\")\n",
    "    plt.title(\"|Δ| vs r\")\n",
    "    plt.tight_layout(); plt.savefig(f\"exports_img/{tag}_disp_vs_r.svg\", bbox_inches=\"tight\"); plt.show()\n",
    "\n",
    "    # 5) Simple 2D projection with ±|Δ| errorbars (XY)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.errorbar(Pc[:,0], Pc[:,1], xerr=np.abs(dx), yerr=np.abs(dy),\n",
    "                 fmt='o', ms=2, ecolor='slategray', alpha=0.6)\n",
    "    plt.xlabel(\"X [m]\"); plt.ylabel(\"Y [m]\"); plt.title(\"X–Y with ±|Δ|\")\n",
    "    plt.gca().set_aspect('equal', adjustable='box'); plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout(); plt.savefig(f\"exports_img/{tag}_xy_errorbars.svg\", bbox_inches=\"tight\"); plt.show()\n",
    "\n",
    "    print(f\"Saved figures with prefix: exports_img/{tag}_*.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97ffac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Safe invocations: create real noisy pair if applicable, then plot whichever pair exists ===\n",
    "\n",
    "def list_available_labels(ts):\n",
    "    print(\"[info] available sets:\", \", \".join(sorted(ts.keys())))\n",
    "\n",
    "def detect_noise_pair(ts):\n",
    "    \"\"\"\n",
    "    Preference order:\n",
    "      1) real_input_clean vs real_input_noisy        (real data with injected noise)\n",
    "      2) ideal vs with_geodetic_distortion           (synthetic EDM)\n",
    "      3) ideal vs with_noise                         (synthetic Gaussian)\n",
    "    \"\"\"\n",
    "    if \"real_input_clean\" in ts and \"real_input_noisy\" in ts:\n",
    "        return \"real_input_clean\", \"real_input_noisy\"\n",
    "    if \"ideal\" in ts and \"with_geodetic_distortion\" in ts:\n",
    "        return \"ideal\", \"with_geodetic_distortion\"\n",
    "    if \"ideal\" in ts and \"with_noise\" in ts:\n",
    "        return \"ideal\", \"with_noise\"\n",
    "    return None, None\n",
    "\n",
    "# 0) pokaż co mamy\n",
    "list_available_labels(transformed_sets)\n",
    "\n",
    "# 1) jeśli mamy real_input, zbuduj jego parę clean/noisy (real-only)\n",
    "if \"real_input\" in transformed_sets:\n",
    "    print(\"[info] 'real_input' detected → building clean/noisy pair for real data.\")\n",
    "    add_real_noise_pair(\n",
    "        transformed_sets,\n",
    "        base_label=\"real_input\",\n",
    "        gaussian_std=0.01,    # <- ustaw parametry wg potrzeb\n",
    "        bias=0.0,\n",
    "        edm=(0.005, 7e-6),    # A=5 mm, B=7 ppm (b=7e-6)\n",
    "        seed=42\n",
    "    )\n",
    "else:\n",
    "    print(\"[info] No 'real_input' found (likely synthetic-only run). Skipping add_real_noise_pair().\")\n",
    "\n",
    "# 2) wybierz dowolną dostępną parę i narysuj wykresy niepewności\n",
    "cl, nl = detect_noise_pair(transformed_sets)\n",
    "if cl is not None:\n",
    "    print(f\"[info] Using noise-only pair: {cl} vs {nl}\")\n",
    "    # gęste chmury real → subsample, syntetyczne → bez subsamplingu\n",
    "    ss = 20000 if cl.startswith(\"real_input\") else None\n",
    "    plot_uncertainty_suite(\n",
    "        transformed_sets,\n",
    "        clean_label=cl,\n",
    "        noisy_label=nl,\n",
    "        prefix=\"uncertainty\",\n",
    "        subsample=ss\n",
    "    )\n",
    "else:\n",
    "    print(\"[warn] No clean/noisy pair found.\")\n",
    "    print(\"      Synthetic: ensure 'ideal' + ('with_geodetic_distortion' or 'with_noise').\")\n",
    "    print(\"      Real: set INPUT_CFG['source'] to 'pcd'/'csv' (creates 'real_input'), then call add_real_noise_pair(...).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6588fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geopoint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
